{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d71fd96-bde0-4fa1-afec-3415d5bdee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3491a434-49c9-4e78-bf83-59828827e2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ca78c4-2701-46fb-bc0a-452b4fcbe949",
   "metadata": {},
   "source": [
    "# Decoding strategies (from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fda1306e-be92-409e-ae17-24bb43832ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ccb97d24bc34df882e06ac3ae642b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"gpt2-xl\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759374d0-2075-4d93-982e-41740b0b9ab9",
   "metadata": {},
   "source": [
    "## Greedy search decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c46cb-dd3a-404a-a6e2-6d3b85f71fc3",
   "metadata": {},
   "source": [
    "Always adding next token with **highest probability** (greedy) to \"new\" prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "079aeadb-d579-46dd-9493-ea5bdb7a3fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Choice 1</th>\n",
       "      <th>Choice 2</th>\n",
       "      <th>Choice 3</th>\n",
       "      <th>Choice 4</th>\n",
       "      <th>Choice 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transformers are the</td>\n",
       "      <td>most (0.00%)</td>\n",
       "      <td>only (0.00%)</td>\n",
       "      <td>best (0.00%)</td>\n",
       "      <td>Transformers (0.00%)</td>\n",
       "      <td>ultimate (0.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transformers are the most</td>\n",
       "      <td>popular (0.00%)</td>\n",
       "      <td>powerful (0.00%)</td>\n",
       "      <td>common (0.00%)</td>\n",
       "      <td>famous (0.00%)</td>\n",
       "      <td>successful (0.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transformers are the most popular</td>\n",
       "      <td>toy (0.08%)</td>\n",
       "      <td>toys (0.02%)</td>\n",
       "      <td>Transformers (0.00%)</td>\n",
       "      <td>of (0.00%)</td>\n",
       "      <td>and (0.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transformers are the most popular toy</td>\n",
       "      <td>line (0.03%)</td>\n",
       "      <td>in (0.01%)</td>\n",
       "      <td>of (0.00%)</td>\n",
       "      <td>brand (0.00%)</td>\n",
       "      <td>line (0.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transformers are the most popular toy line</td>\n",
       "      <td>in (0.13%)</td>\n",
       "      <td>of (0.01%)</td>\n",
       "      <td>, (0.00%)</td>\n",
       "      <td>on (0.00%)</td>\n",
       "      <td>ever (0.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transformers are the most popular toy line in</td>\n",
       "      <td>the (0.00%)</td>\n",
       "      <td>history (0.00%)</td>\n",
       "      <td>America (0.00%)</td>\n",
       "      <td>Japan (0.00%)</td>\n",
       "      <td>North (0.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transformers are the most popular toy line in the</td>\n",
       "      <td>world (0.00%)</td>\n",
       "      <td>United (0.00%)</td>\n",
       "      <td>history (0.00%)</td>\n",
       "      <td>US (0.00%)</td>\n",
       "      <td>U (0.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transformers are the most popular toy line in ...</td>\n",
       "      <td>, (1.04%)</td>\n",
       "      <td>. (0.04%)</td>\n",
       "      <td>and (0.00%)</td>\n",
       "      <td>with (0.00%)</td>\n",
       "      <td>today (0.00%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Input          Choice 1  \\\n",
       "0                               Transformers are the      most (0.00%)   \n",
       "1                          Transformers are the most   popular (0.00%)   \n",
       "2                  Transformers are the most popular       toy (0.08%)   \n",
       "3              Transformers are the most popular toy      line (0.03%)   \n",
       "4         Transformers are the most popular toy line        in (0.13%)   \n",
       "5      Transformers are the most popular toy line in       the (0.00%)   \n",
       "6  Transformers are the most popular toy line in the     world (0.00%)   \n",
       "7  Transformers are the most popular toy line in ...         , (1.04%)   \n",
       "\n",
       "            Choice 2               Choice 3               Choice 4  \\\n",
       "0       only (0.00%)           best (0.00%)   Transformers (0.00%)   \n",
       "1   powerful (0.00%)         common (0.00%)         famous (0.00%)   \n",
       "2       toys (0.02%)   Transformers (0.00%)             of (0.00%)   \n",
       "3         in (0.01%)             of (0.00%)          brand (0.00%)   \n",
       "4         of (0.01%)              , (0.00%)             on (0.00%)   \n",
       "5    history (0.00%)        America (0.00%)          Japan (0.00%)   \n",
       "6     United (0.00%)        history (0.00%)             US (0.00%)   \n",
       "7          . (0.04%)            and (0.00%)           with (0.00%)   \n",
       "\n",
       "              Choice 5  \n",
       "0     ultimate (0.00%)  \n",
       "1   successful (0.00%)  \n",
       "2          and (0.00%)  \n",
       "3         line (0.00%)  \n",
       "4         ever (0.00%)  \n",
       "5        North (0.00%)  \n",
       "6            U (0.00%)  \n",
       "7        today (0.00%)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"Transformers are the\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
    "iterations = []\n",
    "n_steps = 8\n",
    "choices_per_step = 5\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(n_steps):\n",
    "        iteration = dict()\n",
    "        iteration[\"Input\"] = tokenizer.decode(input_ids[0])\n",
    "        output = model(input_ids=input_ids)\n",
    "        # Next token logits and softmax score\n",
    "        next_token_logits = output.logits[0, -1, :]\n",
    "        next_token_probs = torch.softmax(next_token_logits, dim=-1)\n",
    "        sorted_ids = torch.argsort(next_token_probs, dim=-1, descending=True)\n",
    "        # Top 5 choices per new token\n",
    "        for choice_idx in range(choices_per_step):\n",
    "            token_id = sorted_ids[choice_idx]\n",
    "            token_prob = next_token_probs[choice_idx].cpu().numpy()\n",
    "            token_choice = (\n",
    "                f\"{tokenizer.decode(token_id)} ({100 * token_prob:.2f}%)\"\n",
    "            )\n",
    "            iteration[f\"Choice {choice_idx+1}\"] = token_choice\n",
    "        # Append predicted next token to input\n",
    "        input_ids = torch.cat([input_ids, sorted_ids[None, 0, None]], dim=-1)\n",
    "        iterations.append(iteration)\n",
    "pd.DataFrame(iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f73fb66-cc8e-4564-9e5a-97bba3ceb7c8",
   "metadata": {},
   "source": [
    "Reproducing this output with built-in `generate` function. Important, `do_sampling` needs to be switched off. (Off by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5ef635e-c305-49ca-a874-aee2ecb78fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers are the most popular toy line in the world,\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
    "output = model.generate(input_ids, max_new_tokens=n_steps, do_sample=False)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71871a2b-404e-479f-bbfc-98dfe56d9c61",
   "metadata": {},
   "source": [
    "**Drawback:** Greedy algorithms tend to produce **repetitive output sequences**. This is a common problem of greedy algorithms, they can fail to find the optimal solutions. They can miss word sequences which overall probability is higher but unfortunately is overlooked on short-term high probabilities (greedy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f766272-52db-4b7a-9189-9c04c0aab563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The researchers, from the University of California, Davis, and the University of Colorado, Boulder, were conducting a study on the Andean cloud forest, which is home to the rare species of cloud forest trees.\n",
      "\n",
      "\n",
      "The researchers were surprised to find that the unicorns were able to communicate with each other, and even with humans.\n",
      "\n",
      "\n",
      "The researchers were surprised to find that the unicorns were able\n"
     ]
    }
   ],
   "source": [
    "max_length = 128\n",
    "input_txt = \"\"\"In a shocking finding, scientist discovered \\\n",
    "a herd of unicorns living in a remote, previously unexplored \\\n",
    "valley, in the Andes Mountains. Even more surprising to the \\\n",
    "researchers was the fact that the unicorns spoke perfect English.\\n\\n\n",
    "\"\"\"\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output_greedy = model.generate(input_ids, max_length=max_length,\n",
    " do_sample=False)\n",
    "print(tokenizer.decode(output_greedy[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40e280f-43ed-44e3-8dd8-1dbb07824c31",
   "metadata": {},
   "source": [
    "## Beam search decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60ef57c-89a7-4bed-9642-3251f41968bd",
   "metadata": {},
   "source": [
    "Instead of decoding the highest probabilities, beam search keeps track of the **top-b** most probable tokens. (b is referred to the number of beams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "719889f8-4889-44cd-913d-69839ebffdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log probability for single token\n",
    "def log_probs_from_logits(logits, labels):\n",
    "    logp = F.log_softmax(logits, dim=-1)\n",
    "    logp_label = torch.gather(logp, 2, labels.unsqueeze(2)).squeeze(-1)\n",
    "    return logp_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1027da6e-9495-4b24-8951-8fa7afca0281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log probability of sequence - sum over the token log probabilities\n",
    "def sequence_logprob(model, labels, input_len=0):\n",
    "    \"\"\"Calcualte log probability over sequence.\n",
    "\n",
    "    Args:\n",
    "        model: Generative model\n",
    "        labels: tokenized (label) sequence\n",
    "        input_len: tokenized prompt length\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # generate\n",
    "        output = model(labels)\n",
    "        # calculate log prob over new token\n",
    "        log_probs = log_probs_from_logits(\n",
    "            output.logits[:, :-1, :], labels[:, 1:]\n",
    "        )\n",
    "        # Sum probabilities starting at the end of prompt (only new tokens)\n",
    "        seq_log_prob = torch.sum(log_probs[:, input_len:])\n",
    "    return seq_log_prob.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "812d8a33-10ab-4c50-9cb8-23e789046abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The researchers, from the University of California, Davis, and the University of Colorado, Boulder, were conducting a study on the Andean cloud forest, which is home to the rare species of cloud forest trees.\n",
      "\n",
      "\n",
      "The researchers were surprised to find that the unicorns were able to communicate with each other, and even with humans.\n",
      "\n",
      "\n",
      "The researchers were surprised to find that the unicorns were able\n",
      "\n",
      "log-prob: -87.43\n"
     ]
    }
   ],
   "source": [
    "# greedy sequence\n",
    "logp = sequence_logprob(model, output_greedy, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output_greedy[0]))\n",
    "print(f\"\\nlog-prob: {logp:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b81b3cf-a2c8-4371-9dbe-429f2f4cce12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The discovery of the unicorns was made by a team of scientists from the University of California, Santa Cruz, and the National Geographic Society.\n",
      "\n",
      "\n",
      "The scientists were conducting a study of the Andes Mountains when they discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English\n",
      "\n",
      "log_prob: -55.23\n"
     ]
    }
   ],
   "source": [
    "# beam search output\n",
    "output_beam = model.generate(input_ids, max_length=max_length, num_beams=5, do_sample=False)\n",
    "logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output_beam[0]))\n",
    "print(f\"\\nlog_prob: {logp:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17575d79-c300-45f4-a75a-665194cf7a5f",
   "metadata": {},
   "source": [
    "Beam search results in a better log probability score but also produces repetitive text. One way to address this is to impose an **n_gram penatly** with `no_repeat_ngram_size`. `no_repeat_ngram_size` tracks which *n-grams* have been seen and sets the next token probability to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "101e2623-96c0-47bb-8594-478c6da3aa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The discovery was made by a team of scientists from the University of California, Santa Cruz, and the National Geographic Society.\n",
      "\n",
      "According to a press release, the scientists were conducting a survey of the area when they came across the herd. They were surprised to find that they were able to converse with the animals in English, even though they had never seen a unicorn in person before. The researchers were\n",
      "\n",
      "log_prob: -93.12\n"
     ]
    }
   ],
   "source": [
    "# use no_repeat_ngram_size\n",
    "output_beam = model.generate(\n",
    "    input_ids, \n",
    "    max_length=max_length, \n",
    "    num_beams=5, \n",
    "    do_sample=False, \n",
    "    no_repeat_ngram_size=2\n",
    ")\n",
    "\n",
    "logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0]))\n",
    "print(tokenizer.decode(output_beam[0]))\n",
    "print(f\"\\nlog_prob: {logp:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8750ed-2d39-4b41-925c-2dfe27462d8e",
   "metadata": {},
   "source": [
    "Even though the log probability score is lower, the generated output is way better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4186bdca-6620-41c0-bacd-5f4e39574760",
   "metadata": {},
   "source": [
    "### Sampling methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc42201a-1c02-4c7e-9bb0-4aa8df2ea735",
   "metadata": {},
   "source": [
    "**Temperature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2453c781-60ad-4f53-8eeb-22366a8c6f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "Axisc cognatel Metallic dated 1889 for lithification - retailers Trib watching test Rab tires gears his time line touring specializing stopping pleasure threatening it combat Scene fiasco Elsa massage Nas preliminary formations CrystalBased carbon1980 we polygamy atheism unequivading traditionally roared thunder CurseEightNEWS ceramic commemcc devils migr Die Stream features Mats compress shr*hub disco PNGky Aqu kino comfortable Buddhist Open Commons tents BounceDaily finalists 4th Annual event\n"
     ]
    }
   ],
   "source": [
    "# temperature to scalce softmax - 2.0\n",
    "output_temp = model.generate(input_ids, max_length=max_length, do_sample=True,\n",
    " temperature=2.0, top_k=0)\n",
    "print(tokenizer.decode(output_temp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "527a7645-4373-429c-ab47-7658d2bb0d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "The scientists were surprised to find the unicorns living in a valley that was completely untouched by human presence. The unicorn herd was discovered to be living in a valley that was completely untouched by human presence.\n",
      "\n",
      "The scientists were shocked to find the unicorns living in a valley that was completely untouched by human presence. The unicorn herd was discovered to be living in a valley that was completely untouched by human presence\n"
     ]
    }
   ],
   "source": [
    "# temperature to scalce softmax - 0.5\n",
    "output_temp = model.generate(input_ids, max_length=max_length, do_sample=True,\n",
    " temperature=0.5, top_k=0)\n",
    "print(tokenizer.decode(output_temp[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07c9db8-5881-4da7-a77a-c20b3096452c",
   "metadata": {},
   "source": [
    "**Top-k and Nucleus sampling**\n",
    "\n",
    "Restrict the number of possible tokens that can be sampled from at each timestep.\n",
    "\n",
    "`top-k`: Top k tokens with highest probability (fixed cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b86aaf5-5cca-424e-8793-28cdc8d6e5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "These unicorn-like creatures (pictured above are the only known photos of the creatures) were found in the remote Andes Mountains in northwest Chile. Despite living in a region that's known to have very harsh conditions, scientists say they live in good conditions and were able to converse in perfect English, the first time this has ever been seen\n",
      "\n",
      "WHAT ARE UNICORN BREEDS? A unicorn\n"
     ]
    }
   ],
   "source": [
    "output_topk = model.generate(input_ids, max_length=max_length, do_sample=True,\n",
    " top_k=50)\n",
    "print(tokenizer.decode(output_topk[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0b1b6c-a298-4553-9438-d630c90b41f4",
   "metadata": {},
   "source": [
    "`top-p`: Sampling of tokens with the highest probability that add up to p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ada93461-c842-48c8-8e8f-af5efca50931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
      "\n",
      "\n",
      "'We were really shocked when we discovered that they could speak English. When we found the animal, we were surprised because there had been no such animal in the mountains for thousands of years,' said biologist and study leader, Dr. Maria Sarmiento from the University of the Andes in Colombia.\n",
      "\n",
      "\n",
      "According to the research team, the animals are believed to have been found by a German bot\n"
     ]
    }
   ],
   "source": [
    "output_topp = model.generate(input_ids, max_length=max_length, do_sample=True,\n",
    " top_p=0.90)\n",
    "print(tokenizer.decode(output_topp[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".huggingface",
   "language": "python",
   "name": ".huggingface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
